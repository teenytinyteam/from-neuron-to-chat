{
 "cells": [
  {
   "metadata": {
    "collapsed": true
   },
   "cell_type": "markdown",
   "source": "# Positional Embedding",
   "id": "e02237fda9475de2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-07T14:52:07.641611Z",
     "start_time": "2025-09-07T14:52:07.560769Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import re\n",
    "from abc import ABC, abstractmethod\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(99)"
   ],
   "id": "56ab8ec5816b5619",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-07T14:52:07.678419Z",
     "start_time": "2025-09-07T14:52:07.658393Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Tensor:\n",
    "\n",
    "    def __init__(self, data):\n",
    "        self.data = np.array(data)\n",
    "        self.grad = None\n",
    "        self.gradient_fn = lambda: None\n",
    "        self.parents = set()\n",
    "\n",
    "    def gradient(self):\n",
    "        if self.gradient_fn:\n",
    "            self.gradient_fn()\n",
    "\n",
    "        for p in self.parents:\n",
    "            p.gradient()\n",
    "\n",
    "    def shape(self):\n",
    "        return self.data.shape\n",
    "\n",
    "    def size(self):\n",
    "        return np.prod(self.data.shape[1:])\n",
    "\n",
    "    def __add__(self, other):\n",
    "        p = Tensor(self.data + other.data)\n",
    "\n",
    "        def gradient_fn():\n",
    "            self.grad = p.grad\n",
    "            other.grad = p.grad\n",
    "\n",
    "        p.gradient_fn = gradient_fn\n",
    "        p.parents = {self, other}\n",
    "        return p\n",
    "\n",
    "    def __mul__(self, other):\n",
    "        p = Tensor(self.data * other.data)\n",
    "\n",
    "        def gradient_fn():\n",
    "            self.grad = p.grad * other.data\n",
    "            other.grad = p.grad * self.data\n",
    "\n",
    "        p.gradient_fn = gradient_fn\n",
    "        p.parents = {self, other}\n",
    "        return p\n",
    "\n",
    "    def concat(self, other, axis):\n",
    "        p = Tensor(np.concatenate([self.data, other.data], axis=axis))\n",
    "\n",
    "        def gradient_fn():\n",
    "            self.grad, other.grad = np.split(p.grad, [self.data.shape[axis]], axis=axis)\n",
    "\n",
    "        p.gradient_fn = gradient_fn\n",
    "        p.parents = {self, other}\n",
    "        return p"
   ],
   "id": "42e3b987c75169ea",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-07T14:52:07.719651Z",
     "start_time": "2025-09-07T14:52:07.707923Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class DataLoader:\n",
    "\n",
    "    def __init__(self, filename, batch_size, stride):\n",
    "        self.filename = filename\n",
    "        self.batch_size = batch_size\n",
    "        self.stride = stride\n",
    "\n",
    "        with open(self.filename, 'r', encoding='utf-8') as f:\n",
    "            self.text = f.read().lower()\n",
    "\n",
    "        self.vocabulary = sorted(set(self.split_text(self.text)))\n",
    "        self.vocabulary.extend(['<|eos|>', '<|unk|>'])\n",
    "        self.word2index = {word: index for index, word in enumerate(self.vocabulary)}\n",
    "        self.index2word = {index: word for index, word in enumerate(self.vocabulary)}\n",
    "        self.tokens = self.encode(self.text)\n",
    "\n",
    "        self.train()\n",
    "\n",
    "    @staticmethod\n",
    "    def split_text(text):\n",
    "        words = re.split(r'([,.:;?_!\"()\\']|\\s)', text.lower())\n",
    "        return [t.strip() for t in words if t.strip()]\n",
    "\n",
    "    def train(self):\n",
    "        self.features = []\n",
    "        self.labels = []\n",
    "        for i in range(0, len(self.tokens) * 9 // 10 - self.batch_size,\n",
    "                       self.stride):\n",
    "            self.features.append(self.tokens[i: i + self.batch_size])\n",
    "            self.labels.append(self.tokens[i + 1: i + self.batch_size + 1])\n",
    "\n",
    "    def eval(self):\n",
    "        self.features = []\n",
    "        self.labels = []\n",
    "        for i in range(len(self.tokens) * 9 // 10 - self.batch_size + 1,\n",
    "                       len(self.tokens) - self.batch_size,\n",
    "                       self.stride):\n",
    "            self.features.append(self.tokens[i: i + self.batch_size])\n",
    "            self.labels.append(self.tokens[i + 1: i + self.batch_size + 1])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.features[index], self.labels[index]\n",
    "\n",
    "    def encode(self, text):\n",
    "        words = self.split_text(text)\n",
    "        words = [word if word in self.word2index else '<|unk|>' for word in words]\n",
    "        return [self.word2index[word] for word in words]\n",
    "\n",
    "    def decode(self, tokens):\n",
    "        text = \" \".join([self.index2word[index] for index in tokens])\n",
    "        return re.sub(r'\\s+([,.:;?_!\"()\\'])', r'\\1', text)"
   ],
   "id": "5d33e8d61ffd43a8",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-07T14:52:07.768328Z",
     "start_time": "2025-09-07T14:52:07.764777Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Layer(ABC):\n",
    "\n",
    "    def __init__(self):\n",
    "        self.training = True\n",
    "\n",
    "    def __call__(self, *args):\n",
    "        return self.forward(*args)\n",
    "\n",
    "    @abstractmethod\n",
    "    def forward(self, *args):\n",
    "        pass\n",
    "\n",
    "    def parameters(self):\n",
    "        return []\n",
    "\n",
    "    def train(self):\n",
    "        self.training = True\n",
    "\n",
    "    def eval(self):\n",
    "        self.training = False"
   ],
   "id": "686319401a8665a1",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-07T14:52:07.817522Z",
     "start_time": "2025-09-07T14:52:07.812867Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Embedding(Layer):\n",
    "\n",
    "    def __init__(self, vocabulary_size, embedding_size, axis=None):\n",
    "        super().__init__()\n",
    "        self.vocabulary_size = vocabulary_size\n",
    "        self.embedding_size = embedding_size\n",
    "        self.axis = axis\n",
    "\n",
    "        self.weight = Tensor(np.random.rand(embedding_size, vocabulary_size) / vocabulary_size)\n",
    "\n",
    "    def forward(self, x: Tensor):\n",
    "        weights = self.weight.data.T[x.data]\n",
    "        p = Tensor(np.sum(weights, axis=self.axis) if self.axis is not None else weights)\n",
    "\n",
    "        def gradient_fn():\n",
    "            if self.weight.grad is None:\n",
    "                self.weight.grad = np.zeros_like(self.weight.data)\n",
    "            self.weight.grad.T[x.data] += p.grad\n",
    "\n",
    "        p.gradient_fn = gradient_fn\n",
    "        p.parents = {self.weight}\n",
    "        return p\n",
    "\n",
    "    def parameters(self):\n",
    "        return [self.weight]"
   ],
   "id": "fc104b7c2de2d0e",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-07T14:52:07.872916Z",
     "start_time": "2025-09-07T14:52:07.866368Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class GPTEmbedding(Layer):\n",
    "\n",
    "    def __init__(self, vocabulary_size, context_size, embedding_size):\n",
    "        super().__init__()\n",
    "        self.vocabulary_size = vocabulary_size\n",
    "        self.context_size = context_size\n",
    "        self.embedding_size = embedding_size\n",
    "\n",
    "        self.token_embedding = Embedding(self.vocabulary_size, self.embedding_size)\n",
    "        self.positional_embedding = Embedding(self.context_size, self.embedding_size)\n",
    "\n",
    "    def forward(self, x: Tensor):\n",
    "        token = self.token_embedding(x)\n",
    "        position = self.positional_embedding(Tensor(range(self.context_size)))\n",
    "        return token + position"
   ],
   "id": "94a45f91f6c22d",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-07T14:52:07.928539Z",
     "start_time": "2025-09-07T14:52:07.922548Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class GPT(Layer):\n",
    "\n",
    "    def __init__(self, vocabulary_size, context_size, embedding_size):\n",
    "        super().__init__()\n",
    "        self.vocabulary_size = vocabulary_size\n",
    "        self.context_size = context_size\n",
    "        self.embedding_size = embedding_size\n",
    "\n",
    "        self.embedding = GPTEmbedding(self.vocabulary_size, self.context_size, self.embedding_size)\n",
    "\n",
    "    def forward(self, x: Tensor):\n",
    "        return self.embedding(x)"
   ],
   "id": "900a2548475c7ef4",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-07T14:52:07.983082Z",
     "start_time": "2025-09-07T14:52:07.977395Z"
    }
   },
   "cell_type": "code",
   "source": [
    "CONTEXT_SIZE = 4\n",
    "EMBEDDING_SIZE = 3"
   ],
   "id": "7d32d96b99c14e0c",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-07T14:52:08.060166Z",
     "start_time": "2025-09-07T14:52:08.033784Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dataset = DataLoader('../one-day.txt', CONTEXT_SIZE, 1)\n",
    "\n",
    "model = GPT(len(dataset.vocabulary), CONTEXT_SIZE, EMBEDDING_SIZE)\n",
    "\n",
    "print('Embedding weight shape: ', model.embedding.token_embedding.weight.shape())\n",
    "print('Embedding weight: ', model.embedding.token_embedding.weight.data)\n",
    "print('Positional weight shape: ', model.embedding.positional_embedding.weight.shape())\n",
    "print('Positional weight: ', model.embedding.positional_embedding.weight.data)\n",
    "\n",
    "feature, label = dataset[0]\n",
    "\n",
    "prediction = model(Tensor(feature))\n",
    "\n",
    "print('Token shape: ', prediction.shape())\n",
    "print('Tokens: ', prediction.data)"
   ],
   "id": "c5f4af80b0804cfe",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding weight shape:  (3, 267)\n",
      "Embedding weight:  [[2.51789722e-03 1.82800899e-03 3.09174222e-03 1.17776733e-04\n",
      "  3.02640436e-03 2.11841730e-03 1.11469101e-03 1.74890339e-04\n",
      "  3.71021498e-03 2.55645432e-05 2.88311996e-03 2.79688053e-03\n",
      "  1.41362898e-03 1.85073952e-03 3.47920746e-03 1.48110129e-03\n",
      "  3.64777639e-03 1.96410006e-03 3.50610836e-04 3.04609892e-03\n",
      "  7.92834403e-04 2.07620144e-03 1.09464088e-03 3.05671296e-03\n",
      "  3.10128302e-03 8.29877797e-04 2.41511124e-03 3.56485475e-04\n",
      "  1.54180988e-03 3.62791241e-04 5.39367037e-04 7.94742230e-04\n",
      "  1.78522904e-03 2.90688527e-04 8.80313788e-04 2.45430812e-05\n",
      "  3.36570857e-03 2.06829373e-03 6.27515460e-04 3.47894451e-03\n",
      "  2.03029101e-03 1.56398994e-04 1.96583086e-03 2.39753760e-03\n",
      "  2.99871971e-03 3.12703690e-03 9.46188128e-04 3.62649256e-03\n",
      "  1.74621024e-03 9.89105505e-04 2.05759707e-03 1.41323516e-03\n",
      "  7.63027521e-04 3.42869850e-03 3.51751844e-03 3.13668012e-03\n",
      "  1.62093384e-03 2.68207098e-03 3.18855427e-03 2.96055001e-04\n",
      "  1.53542523e-03 2.40288427e-03 3.65712106e-03 2.64152944e-03\n",
      "  2.38434495e-03 7.69238617e-04 1.09762215e-03 5.99288667e-04\n",
      "  1.13832661e-03 2.69103513e-03 3.58794007e-03 5.91094395e-05\n",
      "  1.17076576e-03 1.83193584e-04 3.27629548e-03 2.59834419e-03\n",
      "  3.09572481e-03 3.43950617e-03 5.73477359e-04 1.76040682e-03\n",
      "  2.04594995e-03 1.93353149e-03 2.69819310e-03 3.08061854e-03\n",
      "  8.81148088e-04 3.95280933e-04 2.29917619e-03 9.12570427e-04\n",
      "  3.09717776e-03 1.74355511e-03 2.58812689e-03 1.32885024e-03\n",
      "  3.87514347e-04 1.11939850e-03 6.11269200e-04 8.72000542e-04\n",
      "  2.03901653e-03 1.32925549e-03 2.78894102e-03 2.42756113e-03\n",
      "  2.88403607e-03 2.96004403e-03 1.97223348e-03 9.59897491e-04\n",
      "  3.72795835e-03 3.99338464e-04 1.55408721e-03 5.79101622e-04\n",
      "  1.89917422e-03 3.02200979e-03 1.77813694e-03 1.62599925e-03\n",
      "  1.24233515e-03 2.87447131e-04 2.71245481e-03 2.81405884e-03\n",
      "  2.30351839e-03 3.37894910e-03 4.98636930e-04 7.51532801e-04\n",
      "  3.17690144e-03 2.47609361e-03 1.93421922e-03 2.89356000e-03\n",
      "  2.90795165e-03 2.07814231e-03 2.58251537e-03 9.33098660e-04\n",
      "  2.63432529e-03 1.49610640e-03 2.31426554e-03 2.25013529e-03\n",
      "  2.28742827e-03 2.63330834e-03 2.87973421e-04 7.93475200e-04\n",
      "  1.11779466e-03 3.61824171e-03 2.46297994e-03 6.51988850e-04\n",
      "  2.55340283e-03 3.15004832e-03 3.37100126e-03 7.78913415e-04\n",
      "  3.54889365e-03 8.68019671e-04 5.75935182e-04 2.36242031e-03\n",
      "  1.36964017e-04 2.98084607e-03 5.34846443e-04 3.23936412e-04\n",
      "  3.06733516e-03 3.60775223e-03 2.85026216e-03 3.06912650e-03\n",
      "  3.50893645e-03 1.54996527e-03 1.19437372e-03 2.64899964e-03\n",
      "  2.35153721e-03 2.56562004e-03 2.67089809e-03 2.67792373e-03\n",
      "  8.31477989e-04 3.11625336e-04 1.87415793e-03 3.52098353e-03\n",
      "  2.75082494e-03 6.16008877e-04 2.49089046e-04 2.18374400e-03\n",
      "  2.18460461e-03 2.52571040e-03 9.07665070e-04 1.68210899e-03\n",
      "  2.61809972e-03 5.94019951e-04 7.01445678e-04 1.64354315e-03\n",
      "  9.38169212e-04 3.44380832e-03 7.11237828e-04 1.49704048e-03\n",
      "  3.06168621e-03 1.43836180e-04 2.50230939e-03 5.25937483e-05\n",
      "  3.47627950e-03 4.27707839e-04 5.68817394e-04 2.27949448e-03\n",
      "  3.17324449e-03 1.63435253e-03 1.74301918e-03 3.13227556e-03\n",
      "  1.90878710e-03 1.72534603e-03 1.09976285e-03 1.35738452e-03\n",
      "  1.22807624e-03 2.13049658e-03 2.92872656e-03 2.70398558e-03\n",
      "  2.54177104e-03 3.47760167e-03 3.24760765e-03 3.46359414e-03\n",
      "  1.57486685e-04 1.47497645e-03 2.18532963e-03 1.72982977e-03\n",
      "  2.54438701e-03 3.69818645e-03 5.75073482e-04 1.24792345e-03\n",
      "  3.56975741e-03 1.59866398e-03 1.56209395e-03 3.26296121e-03\n",
      "  1.56271582e-04 4.47641379e-04 4.74499700e-04 3.70602622e-03\n",
      "  3.34782030e-04 1.50738893e-03 3.33756922e-03 1.43909146e-03\n",
      "  8.91516149e-05 1.57077870e-03 3.13851799e-04 2.21365423e-03\n",
      "  1.75132229e-03 1.33473065e-03 3.18056020e-03 3.40956766e-03\n",
      "  1.85527650e-03 1.67619865e-03 3.43635027e-03 3.29031552e-03\n",
      "  3.17106191e-03 2.41374370e-03 1.99187683e-03 3.61372173e-03\n",
      "  1.09448245e-03 1.14628366e-03 3.79892096e-04 1.51025470e-03\n",
      "  1.94150206e-03 3.89249630e-04 1.25295537e-03 1.58214073e-03\n",
      "  3.70555616e-03 3.65953349e-03 4.33262935e-04 1.54172374e-03\n",
      "  2.94258761e-03 2.30060715e-03 2.64230492e-03 3.21287126e-03\n",
      "  1.33382604e-03 2.62289809e-03 2.39601140e-03 2.46207402e-04\n",
      "  2.48969229e-03 1.90967777e-04 8.60440539e-04]\n",
      " [4.13214688e-04 8.68130107e-04 3.56096378e-03 3.22356517e-03\n",
      "  1.09676478e-03 3.57107880e-03 4.54472510e-04 6.76173249e-04\n",
      "  1.70269217e-03 2.05117254e-04 1.53901243e-03 2.13456957e-03\n",
      "  2.91638819e-03 2.86508493e-03 3.74295613e-03 1.98120979e-03\n",
      "  3.11474363e-03 2.70884320e-03 2.87943762e-03 1.09861686e-03\n",
      "  2.12094420e-03 3.02734401e-03 2.04203114e-03 3.20245789e-03\n",
      "  1.88795806e-03 9.43181095e-04 4.17606127e-04 9.65247496e-04\n",
      "  2.31468249e-03 1.72434575e-03 2.77362310e-03 1.41164822e-03\n",
      "  2.88525752e-03 1.20210447e-03 3.65692985e-03 1.11898777e-03\n",
      "  3.23525090e-03 1.60978429e-03 9.17379378e-04 3.58751649e-03\n",
      "  1.46689119e-03 2.69587148e-03 6.21532758e-04 3.61116463e-03\n",
      "  5.19288858e-04 3.27870523e-03 5.52633264e-05 1.18678774e-03\n",
      "  1.78279157e-03 2.68422267e-03 2.61386792e-03 1.03772106e-03\n",
      "  2.80279718e-04 3.63914654e-04 6.51653996e-08 2.86340649e-03\n",
      "  5.08095688e-04 3.05068178e-03 1.03740051e-03 6.57641256e-04\n",
      "  1.73741749e-03 2.76331776e-03 3.17162299e-03 1.95176394e-03\n",
      "  1.08601731e-03 1.58890016e-03 3.57629913e-03 3.00198498e-03\n",
      "  1.43184025e-03 2.60688580e-03 1.59410824e-03 2.91813264e-03\n",
      "  1.06999060e-03 1.55407450e-03 2.32091612e-03 5.77883950e-04\n",
      "  2.73054157e-03 2.49631152e-03 3.69397308e-03 2.70423706e-03\n",
      "  2.33699253e-03 2.20036520e-03 2.43927045e-03 3.58979743e-03\n",
      "  4.11971343e-04 3.32601349e-03 1.20535795e-03 1.70724093e-05\n",
      "  8.79558617e-04 1.96866788e-03 2.07325421e-03 2.04977633e-03\n",
      "  2.21218030e-03 1.20497219e-04 3.74241442e-03 1.59693414e-03\n",
      "  5.97560754e-04 8.34897803e-04 2.70289621e-03 1.24809243e-03\n",
      "  2.10765532e-03 3.56908157e-03 1.74282558e-03 2.09865231e-03\n",
      "  1.16197551e-03 2.72690909e-03 2.69910167e-03 1.47459065e-03\n",
      "  1.41197656e-03 2.52755748e-03 2.52664427e-03 3.17450128e-03\n",
      "  3.63220975e-03 1.11301341e-03 1.27434719e-03 1.35752433e-03\n",
      "  2.14910348e-03 1.07776403e-03 2.23041962e-03 1.99012499e-03\n",
      "  7.23969689e-04 2.90924445e-03 2.87104188e-03 3.46571839e-04\n",
      "  2.21035158e-03 2.38906657e-03 3.75239303e-04 8.17827108e-04\n",
      "  2.73773301e-03 8.63679946e-04 7.15143528e-04 3.71808071e-04\n",
      "  1.97621182e-03 3.72269813e-03 1.80559428e-03 2.97774312e-03\n",
      "  3.11267410e-03 1.93912503e-03 6.06616544e-04 5.48590593e-04\n",
      "  2.74258128e-03 2.93688265e-03 1.57675821e-03 2.03511028e-03\n",
      "  1.72554587e-03 1.57319552e-03 3.09627945e-03 1.48509245e-03\n",
      "  2.53287267e-03 2.19417729e-04 4.66340756e-04 8.64258394e-04\n",
      "  2.25849849e-03 1.53543556e-03 2.71460442e-03 8.89391679e-04\n",
      "  3.62995047e-03 2.24824707e-03 3.35366263e-03 4.76339873e-04\n",
      "  9.22158717e-04 1.78980045e-03 2.19328000e-03 2.48407217e-03\n",
      "  5.81464908e-05 3.08433137e-03 2.82302611e-03 3.68125580e-03\n",
      "  9.57778443e-04 2.54630317e-03 2.57223631e-03 1.88402295e-03\n",
      "  4.79168767e-04 9.72978312e-04 3.73873122e-03 3.54477896e-03\n",
      "  2.79814411e-03 2.56560704e-03 3.33308240e-03 9.90438722e-04\n",
      "  5.46371947e-04 4.99847861e-04 1.82887208e-03 3.57852866e-03\n",
      "  1.82175778e-03 2.97806505e-03 3.04766832e-03 1.16570984e-03\n",
      "  1.48944244e-03 4.45209549e-04 2.60103022e-03 3.66408418e-03\n",
      "  1.09381795e-03 2.79581397e-03 2.10746333e-03 5.69918932e-04\n",
      "  3.16069242e-03 8.31543138e-04 1.06219974e-03 1.62391989e-03\n",
      "  2.00562079e-03 3.15347111e-03 1.68164192e-03 1.78846788e-03\n",
      "  4.22002247e-04 3.41051232e-03 1.16821660e-03 1.57416630e-03\n",
      "  2.88406066e-03 1.16158981e-03 7.66892476e-04 2.06327726e-03\n",
      "  2.06156490e-03 4.01738360e-04 3.23799722e-03 3.31712073e-04\n",
      "  3.49273930e-03 3.53291676e-03 3.42170013e-03 3.20922589e-03\n",
      "  2.79568394e-03 2.98987433e-03 1.18800882e-03 3.90535591e-04\n",
      "  1.43882589e-03 5.03484882e-04 3.04438362e-03 1.80100712e-04\n",
      "  3.73564641e-03 1.65197595e-03 3.70947569e-03 2.49827776e-03\n",
      "  3.56765158e-03 2.12248832e-03 2.49649719e-03 3.32027546e-03\n",
      "  9.88394867e-04 6.07235398e-04 3.48866820e-03 1.86804110e-03\n",
      "  1.50036772e-04 1.07074552e-03 1.08532634e-03 4.69656250e-04\n",
      "  3.53196892e-03 7.42294525e-04 1.99211569e-03 1.93155722e-04\n",
      "  2.51515964e-03 3.51212906e-03 1.99093396e-03 2.39944126e-03\n",
      "  3.15798253e-03 2.70851941e-03 7.47609683e-04 1.47857494e-04\n",
      "  3.66723567e-03 2.09943482e-03 2.91043141e-03 1.58240034e-03\n",
      "  1.43590452e-03 6.94147702e-04 3.20603552e-03 3.10594106e-03\n",
      "  3.96385501e-04 1.77500308e-03 2.33887551e-03]\n",
      " [3.45632578e-03 1.22454186e-03 2.00162051e-03 1.52562781e-03\n",
      "  7.68987826e-04 1.67789030e-03 2.47272083e-04 3.30686802e-03\n",
      "  3.07544097e-03 1.44888284e-03 1.59196860e-03 1.90208978e-03\n",
      "  2.94365972e-03 3.69299976e-03 6.18876199e-04 3.27861619e-03\n",
      "  8.95059435e-04 3.30800061e-03 6.58292845e-04 2.07644096e-03\n",
      "  2.67595157e-03 2.68745080e-03 2.04945361e-03 3.72707503e-03\n",
      "  2.37912894e-03 3.04586887e-03 8.31559997e-04 3.70742760e-04\n",
      "  2.60419491e-03 2.06074508e-03 7.20141495e-04 6.29281323e-04\n",
      "  3.49334811e-03 1.06184220e-04 1.36412035e-03 2.54442599e-05\n",
      "  1.06964091e-03 3.12236280e-03 1.00745379e-03 1.11268281e-03\n",
      "  1.40943552e-03 2.66712085e-03 8.18271270e-04 1.71215624e-03\n",
      "  1.05846995e-04 1.54347376e-03 2.20104506e-04 1.21307846e-03\n",
      "  3.79465464e-04 3.64817657e-03 5.65620688e-05 2.26056848e-03\n",
      "  2.94754417e-04 1.41143060e-03 2.96796990e-03 1.01089127e-03\n",
      "  3.17266565e-03 1.73728319e-03 5.49369951e-04 8.78697487e-04\n",
      "  1.68754097e-03 3.26455520e-03 5.06495906e-04 7.32026162e-04\n",
      "  1.91918322e-03 3.01789317e-03 2.94300930e-03 2.50767381e-03\n",
      "  6.21955776e-04 2.39399931e-03 3.00221838e-03 2.20590589e-03\n",
      "  2.26955416e-03 3.34149133e-03 1.62403966e-04 3.96155865e-04\n",
      "  3.11878249e-03 1.19450603e-03 2.17987070e-03 1.35749698e-03\n",
      "  1.29869706e-03 2.72952837e-03 1.02363697e-03 1.92480472e-03\n",
      "  3.01289633e-03 3.67602235e-03 1.63460579e-04 1.73332499e-03\n",
      "  2.11338606e-03 6.99849864e-04 2.25170940e-03 2.52412587e-03\n",
      "  3.24619320e-03 3.31958284e-03 2.88351243e-03 1.59710911e-03\n",
      "  2.35029088e-03 2.09055151e-03 1.32768876e-04 4.07864611e-04\n",
      "  3.27382152e-03 1.49032903e-03 1.65909611e-03 2.09063775e-03\n",
      "  8.86626966e-04 2.57881069e-03 2.10711416e-03 1.88298857e-04\n",
      "  2.70868501e-03 2.03985348e-03 1.99777953e-03 3.72068832e-03\n",
      "  7.72408924e-04 1.20933146e-03 2.54722695e-03 9.80597146e-04\n",
      "  3.61403250e-03 3.06022945e-03 1.10830418e-03 3.58377535e-03\n",
      "  2.58084594e-03 1.50270430e-03 3.60657317e-03 9.91756277e-04\n",
      "  2.86157155e-03 2.36831908e-03 2.91082487e-03 1.76330156e-03\n",
      "  1.94054483e-03 5.22635266e-05 2.87373715e-03 2.86100797e-04\n",
      "  1.39243913e-03 1.36587339e-03 3.42948227e-03 7.46203372e-04\n",
      "  3.44083310e-03 4.26872628e-04 2.80062495e-03 5.46687882e-04\n",
      "  3.26751855e-03 2.56217069e-03 3.59040599e-03 2.38192560e-04\n",
      "  9.31585743e-04 2.03093611e-03 8.10346772e-04 5.93008840e-04\n",
      "  3.17036081e-03 2.62123971e-03 1.02341639e-03 1.45518951e-03\n",
      "  2.92107219e-03 2.22378762e-03 1.60941836e-03 2.96469118e-03\n",
      "  2.56616859e-04 1.37097714e-03 1.72026729e-03 3.12325924e-03\n",
      "  1.95931699e-03 3.52270081e-03 2.88929529e-04 3.74279081e-03\n",
      "  3.70697798e-03 3.02948908e-03 3.27848407e-03 3.24310441e-03\n",
      "  5.66019776e-04 3.48025359e-03 2.53044783e-03 2.23630705e-03\n",
      "  3.70356964e-03 9.52097390e-04 3.71914190e-03 3.73015955e-03\n",
      "  3.44047302e-03 9.29759269e-04 3.29375286e-05 1.59681591e-03\n",
      "  3.42340576e-03 2.96074878e-03 8.85207227e-04 1.32654268e-03\n",
      "  1.87329409e-03 1.47825301e-03 3.43884033e-03 1.58667063e-03\n",
      "  1.04237211e-03 1.73038056e-03 2.27568842e-03 1.98721122e-03\n",
      "  3.22677126e-03 1.16109356e-03 3.62765378e-03 2.87543413e-03\n",
      "  1.15438459e-03 2.60942371e-03 3.73603222e-03 3.49255527e-03\n",
      "  2.54854816e-03 6.57998329e-04 9.68938766e-04 1.41960339e-03\n",
      "  2.37986532e-03 1.93635128e-03 1.47227116e-03 1.15845962e-03\n",
      "  5.60440026e-04 2.79434745e-03 9.81464471e-04 3.78487568e-04\n",
      "  9.44982938e-04 3.95898476e-04 2.99603944e-03 9.45287662e-04\n",
      "  5.39635422e-04 1.03932310e-03 3.47145054e-03 2.29385970e-03\n",
      "  3.06871098e-03 3.41752637e-03 3.30730714e-03 2.82978995e-03\n",
      "  1.49701201e-03 2.09868947e-03 1.25189785e-03 1.08898987e-03\n",
      "  1.96302467e-03 6.51089830e-04 3.21695236e-03 1.90671723e-03\n",
      "  3.35504384e-03 4.21441456e-04 6.02172253e-04 1.68690510e-03\n",
      "  2.34917988e-03 2.44200128e-03 3.39726359e-03 3.08866827e-03\n",
      "  2.62793051e-03 1.99231473e-03 1.83407560e-03 2.07206488e-03\n",
      "  3.04197021e-03 1.08827816e-03 3.31073488e-03 1.40067763e-03\n",
      "  1.11888551e-03 3.13588491e-03 2.56191245e-03 2.78300889e-03\n",
      "  3.13854391e-03 1.61752889e-03 1.90599512e-03 2.00011392e-03\n",
      "  1.66567485e-03 7.23054367e-04 4.95885218e-04 1.11571466e-03\n",
      "  3.70998016e-03 2.36228480e-04 2.47606803e-03 2.06371306e-03\n",
      "  4.60946022e-04 2.26004513e-03 7.68244435e-04]]\n",
      "Positional weight shape:  (3, 4)\n",
      "Positional weight:  [[0.16105991 0.18535869 0.23491009 0.15234725]\n",
      " [0.22014201 0.03668587 0.21660975 0.04035918]\n",
      " [0.06837795 0.20199572 0.15401961 0.13479406]]\n",
      "Token shape:  (4, 3)\n",
      "Tokens:  [[0.16404076 0.22036143 0.07099919]\n",
      " [0.18565475 0.03734351 0.20287442]\n",
      " [0.23519754 0.21772277 0.15522895]\n",
      " [0.15568482 0.04340357 0.13604595]]\n"
     ]
    }
   ],
   "execution_count": 9
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
