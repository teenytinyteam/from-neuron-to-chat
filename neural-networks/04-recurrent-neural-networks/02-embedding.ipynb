{
 "cells": [
  {
   "metadata": {
    "collapsed": true
   },
   "cell_type": "markdown",
   "source": "# Embedding",
   "id": "4eb7148275af8f2b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-07T02:57:03.194990Z",
     "start_time": "2025-09-07T02:57:03.123330Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import csv\n",
    "import re\n",
    "from abc import ABC, abstractmethod\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(99)"
   ],
   "id": "1e27d7c0f0d0a516",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-07T02:57:03.213155Z",
     "start_time": "2025-09-07T02:57:03.206562Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Tensor:\n",
    "\n",
    "    def __init__(self, data):\n",
    "        self.data = np.array(data)\n",
    "        self.grad = None\n",
    "        self.gradient_fn = lambda: None\n",
    "        self.parents = set()\n",
    "\n",
    "    def gradient(self):\n",
    "        if self.gradient_fn:\n",
    "            self.gradient_fn()\n",
    "\n",
    "        for p in self.parents:\n",
    "            p.gradient()\n",
    "\n",
    "    def shape(self):\n",
    "        return self.data.shape\n",
    "\n",
    "    def size(self):\n",
    "        return np.prod(self.data.shape[1:])"
   ],
   "id": "aa38e307820f7ed7",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-07T02:57:03.266750Z",
     "start_time": "2025-09-07T02:57:03.256197Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class DataLoader:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.reviews = []\n",
    "        self.sentiments = []\n",
    "        with open('reviews.csv', 'r', encoding='utf-8') as f:\n",
    "            reader = csv.reader(f)\n",
    "            next(reader)\n",
    "            for _, row in enumerate(reader):\n",
    "                self.reviews.append(row[0])\n",
    "                self.sentiments.append(row[1])\n",
    "\n",
    "        split_reviews = []\n",
    "        for r in self.reviews:\n",
    "            split_reviews.append(self.clean_text(r.lower()).split())\n",
    "\n",
    "        self.vocabulary = set(w for r in split_reviews for w in r)\n",
    "        self.word2index = {w: idx for idx, w in enumerate(self.vocabulary)}\n",
    "        self.index2word = {idx: w for idx, w in enumerate(self.vocabulary)}\n",
    "        self.tokens = [[self.word2index[w] for w in r if w in self.word2index] for r in split_reviews]\n",
    "\n",
    "        self.train()\n",
    "\n",
    "    @staticmethod\n",
    "    def clean_text(text):\n",
    "        txt = re.sub(r'<[^>]+>', '', text)\n",
    "        txt = re.sub(r'[^a-zA-Z0-9\\s]', '', txt)\n",
    "        return txt\n",
    "\n",
    "    def encode(self, text):\n",
    "        words = self.clean_text(text.lower()).split()\n",
    "        return [self.word2index[word] for word in words]\n",
    "\n",
    "    def decode(self, tokens):\n",
    "        return \" \".join([self.index2word[index] for index in tokens])\n",
    "\n",
    "    def train(self):\n",
    "        self.features = [list(set(idx)) for idx in self.tokens[:-10]]\n",
    "        self.labels = [0 if idx == \"negative\" else 1 for idx in self.sentiments[:-10]]\n",
    "\n",
    "    def eval(self):\n",
    "        self.features = [list(set(idx)) for idx in self.tokens[-10:]]\n",
    "        self.labels = [0 if idx == \"negative\" else 1 for idx in self.sentiments[-10:]]\n",
    "\n",
    "    def __len__(self):  # 3\n",
    "        return len(self.features)\n",
    "\n",
    "    def __getitem__(self, index):  # 4\n",
    "        return (Tensor(self.features[index: index + 1]),\n",
    "                Tensor(self.labels[index: index + 1]))"
   ],
   "id": "6d32fc704427151e",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-07T02:57:03.316585Z",
     "start_time": "2025-09-07T02:57:03.311703Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Layer(ABC):\n",
    "\n",
    "    def __init__(self):\n",
    "        self.training = True\n",
    "\n",
    "    def __call__(self, x: Tensor):\n",
    "        return self.forward(x)\n",
    "\n",
    "    @abstractmethod\n",
    "    def forward(self, x: Tensor):\n",
    "        pass\n",
    "\n",
    "    def parameters(self):\n",
    "        return []\n",
    "\n",
    "    def train(self):\n",
    "        self.training = True\n",
    "\n",
    "    def eval(self):\n",
    "        self.training = False"
   ],
   "id": "7487a12facbafc3b",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-07T02:57:03.376838Z",
     "start_time": "2025-09-07T02:57:03.362515Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Linear(Layer):\n",
    "\n",
    "    def __init__(self, in_size, out_size):\n",
    "        super().__init__()\n",
    "        self.in_size = in_size\n",
    "        self.out_size = out_size\n",
    "\n",
    "        self.weight = Tensor(np.random.rand(out_size, in_size) / in_size)\n",
    "        self.bias = Tensor(np.zeros(out_size))\n",
    "\n",
    "    def forward(self, x: Tensor):\n",
    "        p = Tensor(x.data @ self.weight.data.T + self.bias.data)\n",
    "\n",
    "        def gradient_fn():\n",
    "            self.weight.grad = p.grad.T @ x.data\n",
    "            self.bias.grad = np.sum(p.grad, axis=0)\n",
    "            x.grad = p.grad @ self.weight.data\n",
    "\n",
    "        p.gradient_fn = gradient_fn\n",
    "        p.parents = {self.weight, self.bias, x}\n",
    "        return p\n",
    "\n",
    "    def parameters(self):\n",
    "        return [self.weight, self.bias]"
   ],
   "id": "26ef31ca8764a5bd",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-07T02:57:03.417440Z",
     "start_time": "2025-09-07T02:57:03.412207Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Sequential(Layer):\n",
    "\n",
    "    def __init__(self, layers):\n",
    "        super().__init__()\n",
    "        self.layers = layers\n",
    "\n",
    "    def forward(self, x: Tensor):\n",
    "        for l in self.layers:\n",
    "            x = l(x)\n",
    "        return x\n",
    "\n",
    "    def parameters(self):\n",
    "        return [p for l in self.layers for p in l.parameters()]\n",
    "\n",
    "    def train(self):\n",
    "        for l in self.layers:\n",
    "            l.train()\n",
    "\n",
    "    def eval(self):\n",
    "        for l in self.layers:\n",
    "            l.eval()"
   ],
   "id": "19c71686e2c46773",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-07T02:57:03.474118Z",
     "start_time": "2025-09-07T02:57:03.464786Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Embedding(Layer):\n",
    "\n",
    "    def __init__(self, vocabulary_size, embedding_size, axis=1):\n",
    "        super().__init__()\n",
    "        self.vocabulary_size = vocabulary_size\n",
    "        self.embedding_size = embedding_size\n",
    "        self.axis = axis\n",
    "\n",
    "        self.weight = Tensor(np.random.rand(embedding_size, vocabulary_size) / vocabulary_size)\n",
    "\n",
    "    def forward(self, x: Tensor):\n",
    "        p = Tensor(np.sum(self.weight.data.T[x.data], axis=self.axis))\n",
    "\n",
    "        def gradient_fn():\n",
    "            if self.weight.grad is None:\n",
    "                self.weight.grad = np.zeros_like(self.weight.data)\n",
    "            self.weight.grad.T[x.data] += p.grad\n",
    "\n",
    "        p.gradient_fn = gradient_fn\n",
    "        p.parents = {self.weight}\n",
    "        return p\n",
    "\n",
    "    def parameters(self):\n",
    "        return [self.weight]"
   ],
   "id": "c602ae775a83bfc0",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-07T02:57:03.528472Z",
     "start_time": "2025-09-07T02:57:03.522022Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Tanh(Layer):\n",
    "\n",
    "    def forward(self, x: Tensor):\n",
    "        p = Tensor(np.tanh(x.data))\n",
    "\n",
    "        def gradient_fn():\n",
    "            x.grad = p.grad * (1 - p.data ** 2)\n",
    "\n",
    "        p.gradient_fn = gradient_fn\n",
    "        p.parents = {x}\n",
    "        return p"
   ],
   "id": "89ba6727599f8772",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-07T02:57:03.587124Z",
     "start_time": "2025-09-07T02:57:03.578586Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Sigmoid(Layer):\n",
    "\n",
    "    def __init__(self, clip_range=(-100, 100)):\n",
    "        super().__init__()\n",
    "        self.clip_range = clip_range\n",
    "\n",
    "    def forward(self, x: Tensor):\n",
    "        z = np.clip(x.data, self.clip_range[0], self.clip_range[1])\n",
    "        p = Tensor(1 / (1 + np.exp(-z)))\n",
    "\n",
    "        def gradient_fn():\n",
    "            x.grad = p.grad * p.data * (1 - p.data)\n",
    "\n",
    "        p.gradient_fn = gradient_fn\n",
    "        p.parents = {x}\n",
    "        return p"
   ],
   "id": "5883352f57f41689",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-07T02:57:03.639446Z",
     "start_time": "2025-09-07T02:57:03.632627Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class BCELoss:\n",
    "\n",
    "    def __call__(self, p: Tensor, y: Tensor):\n",
    "        clipped = np.clip(p.data, 1e-7, 1 - 1e-7)\n",
    "        bce = Tensor(-np.mean(y.data * np.log(clipped)\n",
    "                              + (1 - y.data) * np.log(1 - clipped)))\n",
    "\n",
    "        def gradient_fn():\n",
    "            p.grad = (clipped - y.data) / (clipped * (1 - clipped) * len(p.data))\n",
    "\n",
    "        bce.gradient_fn = gradient_fn\n",
    "        bce.parents = {p}\n",
    "        return bce"
   ],
   "id": "c487ec86d20daf32",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-07T02:57:03.686818Z",
     "start_time": "2025-09-07T02:57:03.683276Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class SGD:\n",
    "\n",
    "    def __init__(self, parameters, lr):\n",
    "        self.parameters = parameters\n",
    "        self.lr = lr\n",
    "\n",
    "    def backward(self):\n",
    "        for p in self.parameters:\n",
    "            p.data -= p.grad * self.lr"
   ],
   "id": "4967ed4f06a47973",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-07T02:57:03.740707Z",
     "start_time": "2025-09-07T02:57:03.735085Z"
    }
   },
   "cell_type": "code",
   "source": [
    "LEARNING_RATE = 0.1\n",
    "EPOCHS = 10"
   ],
   "id": "fb4c7fca25c1183a",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-07T02:57:04.032120Z",
     "start_time": "2025-09-07T02:57:03.796279Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dataset = DataLoader()\n",
    "\n",
    "model = Sequential([Embedding(len(dataset.vocabulary), 64),\n",
    "                    Tanh(),\n",
    "                    Linear(64, 16),\n",
    "                    Tanh(),\n",
    "                    Linear(16, 1),\n",
    "                    Sigmoid()])\n",
    "loss = BCELoss()\n",
    "sgd = SGD(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    for i in range(len(dataset)):\n",
    "        feature, label = dataset[i]\n",
    "\n",
    "        prediction = model(feature)\n",
    "        error = loss(prediction, label)\n",
    "\n",
    "        error.gradient()\n",
    "        sgd.backward()\n",
    "\n",
    "print(f'Prediction: {prediction.data}')\n",
    "print(f'Error: {error.data}')"
   ],
   "id": "4eaa50105fde16b7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: [[0.99915852]]\n",
      "Error: 0.0008418313188558764\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-07T02:57:04.056085Z",
     "start_time": "2025-09-07T02:57:04.048258Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dataset.eval()\n",
    "\n",
    "result = 0\n",
    "for i in range(len(dataset)):\n",
    "    feature, label = dataset[i]\n",
    "\n",
    "    prediction = model(feature)\n",
    "    if np.abs(prediction.data - label.data) < 0.5:\n",
    "        result += 1\n",
    "print(f'Result: {result} of {len(dataset)}')"
   ],
   "id": "61c99dfb452a445b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: 10 of 10\n"
     ]
    }
   ],
   "execution_count": 14
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
